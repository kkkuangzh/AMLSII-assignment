{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation on DIV2K validation set  (Model using perceptual loss)\n",
    "\n",
    "Evaluate two metrics PSNR and SSIM of trained models on 100 validation images of bicubic and unknown degradations at scale of 2 and 4.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import config\n",
    "\n",
    "gpu_devices = config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "for device in gpu_devices: config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load testing images from directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "# load testing images from directory\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# LR_valid_path = './datasets/DIV2K_valid_LR_unknown/X2/'\n",
    "# LR_valid_path = './datasets/DIV2K_valid_LR_unknown/X4/'\n",
    "# LR_valid_path = './datasets/DIV2K_valid_LR_bicubic/X4/'\n",
    "\n",
    "LR_valid_path = './datasets/DIV2K_valid_LR_bicubic/X2/'\n",
    "HR_valid_path = './datasets/DIV2K_valid_HR//'\n",
    "\n",
    "LR_train_imgs = []\n",
    "HR_train_imgs = []\n",
    "\n",
    "for path, subpath, files in os.walk(LR_train_path):\n",
    "    files.sort()\n",
    "    for i in files:\n",
    "        if i == '.DS_Store':\n",
    "            continue\n",
    "        img = Image.open(LR_train_path + i)\n",
    "        LR_train_imgs.append(np.asarray(img))\n",
    "\n",
    "for path, subpath, files in os.walk(HR_train_path):\n",
    "    files.sort()\n",
    "    for i in files:\n",
    "        if i == '.DS_Store':\n",
    "            continue\n",
    "        img = Image.open(HR_train_path + i)\n",
    "        HR_train_imgs.append(np.asarray(img)) \n",
    "\n",
    "print(len(LR_train_imgs))\n",
    "print(len(HR_train_imgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define perceptual_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# define the perceptual_loss so that the X2 and X4 models can be loaded\n",
    "\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.layers import Input, Lambda\n",
    "from keras.models import Model\n",
    "import keras\n",
    "\n",
    "def get_VGG19(input_size):\n",
    "    vgg_inp = Input(input_size)\n",
    "    vgg = VGG19(include_top=False, input_tensor=vgg_inp)\n",
    "    for l in vgg.layers: \n",
    "        l.trainable = False\n",
    "    vgg_outp = vgg.get_layer('block2_conv2').output \n",
    "    \n",
    "    return vgg_inp, vgg_outp\n",
    "\n",
    "def perceptual_loss_x2(y_true, y_pred):\n",
    "    \n",
    "    y_t = vgg_content1(y_true)\n",
    "    y_p = vgg_content1(y_pred)\n",
    "    loss = keras.losses.mean_squared_error(y_t, y_p)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "def perceptual_loss_x4(y_true, y_pred):\n",
    "    \n",
    "    y_t = vgg_content2(y_true)\n",
    "    y_p = vgg_content2(y_pred)\n",
    "    loss = keras.losses.mean_squared_error(y_t, y_p)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "vgg_inp, vgg_outp = get_VGG19(input_size=(96,96,3))\n",
    "vgg_content1 = Model(vgg_inp, vgg_outp)\n",
    "vgg_inp, vgg_outp = get_VGG19(input_size=(192,192,3))\n",
    "vgg_content2 = Model(vgg_inp, vgg_outp)\n",
    "#vgg_content.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load trained model for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('./model_and_history/final3_perceptual_unknown_4848_12000_subpixel_X2.h5', \n",
    "                   custom_objects={'tf': tf, 'perceptual_loss_x2':perceptual_loss_x2})\n",
    "\n",
    "#model = load_model('./model_and_history/final3_perceptual_unknown_4848_12000_subpixel_X4.h5', \n",
    "#                   custom_objects={'tf': tf, 'perceptual_loss_x2':perceptual_loss_x2, \n",
    "#                                   'perceptual_loss_x4':perceptual_loss_x4})\n",
    "\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normaliza imgs from 0~255 to 0~1\n",
    "\n",
    "def normalize(imgs):\n",
    "    return imgs / 255\n",
    "\n",
    "def denormalize(imgs):\n",
    "    imgs = imgs * 255\n",
    "    return imgs.astype(np.uint8)\n",
    "\n",
    "for i in range(len(LR_valid_imgs)):\n",
    "    #LR_valid_imgs[i] = LR_valid_imgs[i]/255\n",
    "    LR_valid_imgs[i] = normalize(LR_valid_imgs[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use trained model to predict test images\n",
    "Smaller stride can result in better performance but cost more time to recover as more patches are involved. Time needed to predict 100 validation images are recorded with corresponding stride."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time cost to predict:  18.158096313476562 s\n"
     ]
    }
   ],
   "source": [
    "# predict and reconstruct test images\n",
    "# stride should be smaller than patch size to cover all the pixels\n",
    "\n",
    "from extract_patches import *\n",
    "\n",
    "test_num = 100\n",
    "patch_height = 48\n",
    "patch_width = 48\n",
    "stride = 10\n",
    "up_scale = 2\n",
    "\n",
    "import time\n",
    "\n",
    "time_start=time.time()\n",
    "\n",
    "predicted_HR_list = test_patch(LR_valid_imgs, test_num, patch_height, patch_width, stride, model, up_scale)\n",
    "\n",
    "time_end=time.time()\n",
    "print('Time cost to predict: ', time_end-time_start, 's')\n",
    "\n",
    "for i in range(len(predicted_HR_list)):\n",
    "    predicted_HR_list[i] = denormalize(predicted_HR_list[i])\n",
    "\n",
    "# perceptual bi x2\n",
    "# stride=30, test_num=100, Time cost to predict:  280.6533057689667 s\n",
    "\n",
    "# perceptual bi x4\n",
    "# stride=30, test_num=100, Time cost to predict:  142.2729160785675 s\n",
    "\n",
    "# perceptual unknown x2\n",
    "# stride=30, test_num=100, Time cost to predict:  259.84274101257324 s\n",
    "\n",
    "# perceptual unknown x4\n",
    "# stride=30, test_num=100, Time cost to predict:  143.250426530838 s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSNR:  [28.19379978797455]\n",
      "SSIM:  [0.5385354790849162]\n"
     ]
    }
   ],
   "source": [
    "# compare with HR images \n",
    "# calculate PSNR(peak_signal_noise_ratio) and SSIM(structural_similarity) metrics\n",
    "\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
    "\n",
    "PSNR_val = []\n",
    "SSIM_val = []\n",
    "\n",
    "for i in range(len(predicted_HR_list)):\n",
    "    PSNR = peak_signal_noise_ratio(HR_valid_imgs[i], predicted_HR_list[i])\n",
    "    SSIM = structural_similarity(HR_valid_imgs[i], predicted_HR_list[i], multichannel=True)\n",
    "    PSNR_val.append(PSNR)\n",
    "    SSIM_val.append(SSIM)\n",
    "\n",
    "print('PSNR: ', PSNR_val)\n",
    "print('SSIM: ', SSIM_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save evaluation results\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('./evaluation/unknown_x4_perceptual_psnr_stride30.pkl','wb') as f2:\n",
    "    pickle.dump(PSNR_val, f2)\n",
    "\n",
    "with open('./evaluation/unknown_x4_perceptual_ssim_stride30.pkl','wb') as f3:\n",
    "    pickle.dump(SSIM_val, f3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compare the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./evaluation/bi_x4_perceptual_psnr_stride30.pkl','rb') as f:\n",
    "    psnr_res = pickle.load(f)\n",
    "with open('./evaluation/bi_x4_perceptual_ssim_stride30.pkl','rb') as f:\n",
    "    ssim_res = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "psnr_max: 32.981269088058646 , and image index is: 42\n",
      "psnr_min: 16.60940354909153 , and image index is: 94\n",
      "psnr_median: 21.904707620288484\n",
      "psnr_mean: 22.01498075258402\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print('psnr_max:', max(psnr_res), ', and image index is:', psnr_res.index(max(psnr_res)))\n",
    "print('psnr_min:', min(psnr_res), ', and image index is:', psnr_res.index(min(psnr_res)))\n",
    "print('psnr_median:', np.median(psnr_res))\n",
    "print('psnr_mean:', np.mean(psnr_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssim_max: 0.8970702974687187 , and image index is: 42\n",
      "ssim_min: 0.32360193413110966 , and image index is: 6\n",
      "ssim_median: 0.5374477106387275\n",
      "ssim_mean: 0.5308737822804946\n"
     ]
    }
   ],
   "source": [
    "print('ssim_max:', max(ssim_res), ', and image index is:', ssim_res.index(max(ssim_res)))\n",
    "print('ssim_min:', min(ssim_res), ', and image index is:', ssim_res.index(min(ssim_res)))\n",
    "print('ssim_median:', np.median(ssim_res))\n",
    "print('ssim_mean:', np.mean(ssim_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
